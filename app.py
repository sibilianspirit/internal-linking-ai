import streamlit as st
import pandas as pd
from openai import OpenAI
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import CrossEncoder
import time
from io import BytesIO

# --- Konfiguracja strony Streamlit ---
st.set_page_config(page_title="AI do Linkowania WewnÄ™trznego", layout="centered")
st.title("ðŸ¤– AI do Linkowania WewnÄ™trznego")

# --- StaÅ‚e konfiguracyjne (wspÃ³lne dla obu trybÃ³w) ---
EMBEDDING_MODEL = 'text-embedding-3-large'
RERANKER_MODEL = 'jinaai/jina-reranker-v2-base-multilingual' 
NUM_CANDIDATES = 10
NUM_FINAL_RESULTS = 5

# --- Funkcje pomocnicze (wspÃ³lne dla obu trybÃ³w) ---

@st.cache_data
def get_embeddings(texts: list[str], model: str, api_key: str, progress_text_prefix: str) -> list[list[float]]:
    client = OpenAI(api_key=api_key)
    embeddings = []
    batch_size = 100
    progress_bar = st.progress(0, text=f"{progress_text_prefix}: Generowanie embeddingÃ³w...")
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch = [text if isinstance(text, str) and text.strip() != "" else " " for text in batch]
        response = client.embeddings.create(input=batch, model=model)
        embeddings.extend([item.embedding for item in response.data])
        progress_val = min((i + batch_size) / len(texts), 1.0)
        progress_text = f"{progress_text_prefix}: Przetworzono {min(i + batch_size, len(texts))}/{len(texts)} URLi."
        progress_bar.progress(progress_val, text=progress_text)
        time.sleep(0.5)
    progress_bar.empty()
    return embeddings

@st.cache_resource
def load_reranker_model(model_name: str):
    """Åaduje model CrossEncoder z pamiÄ™ci podrÄ™cznej."""
    return CrossEncoder(model_name, max_length=1024, trust_remote_code=True)

# --- WybÃ³r trybu analizy ---
analysis_mode = st.radio(
    "Wybierz tryb analizy:",
    ("Linkowanie WewnÄ™trzne (jeden plik)", "Linkowanie KrzyÅ¼owe (dwa pliki)"),
    horizontal=True
)


# ==============================================================================
# TRYB 1: LINKOWANIE WEWNÄ˜TRZNE (JEDEN PLIK)
# ==============================================================================
if analysis_mode == "Linkowanie WewnÄ™trzne (jeden plik)":
    st.info(
        """
        **Etapy procesu:**
        1. **Wyszukiwanie -** model embeddingowy znajduje 10 potencjalnych kandydatÃ³w.
        2. **Reranking -** model rerankingowy precyzyjnie ocenia tych 10 kandydatÃ³w, aby wybraÄ‡ 5 najlepszych.

        **Wymagania:**
        1. **Plik CSV -** musi zawieraÄ‡ kolumny: `url`, `h1`, `title`.
        2. **WybÃ³r pomiÄ™dzy h1 i title -** wskaÅ¼, na ktÃ³rej kolumnie ma bazowaÄ‡ model.
        """
    )

    try:
        api_key = st.secrets["OPENAI_API_KEY"]
    except KeyError:
        st.error("BÅ‚Ä…d: Klucz OPENAI_API_KEY nie zostaÅ‚ ustawiony w sekretach aplikacji!")
        st.info("PrzejdÅº do ustawieÅ„ aplikacji w Streamlit Community Cloud i dodaj swÃ³j klucz.")
        st.stop()

    uploaded_file = st.file_uploader("1. Wgraj plik CSV", type=["csv"], help="Upewnij siÄ™, Å¼e plik zawiera kolumny: 'url', 'title' oraz 'h1'.")
    column_to_embed = st.selectbox("2. Wybierz kolumnÄ™ do analizy", ("h1", "title"), disabled=uploaded_file is None)

    if st.button("ðŸš€ Uruchom analizÄ™ wewnÄ™trznÄ…", disabled=(uploaded_file is None)):
        try:
            df = pd.read_csv(uploaded_file)
            required_columns = ['url', 'title', 'h1']
            if not all(col in df.columns for col in required_columns):
                st.error(f"BÅ‚Ä…d: Plik CSV musi zawieraÄ‡ kolumny: {', '.join(required_columns)}")
            else:
                st.write("âœ… **Etap 1/4:** Generowanie embeddingÃ³w...")
                texts_to_embed = df[column_to_embed].fillna(" ").tolist()
                df['embedding'] = get_embeddings(texts_to_embed, EMBEDDING_MODEL, api_key, "Etap 1")
                
                st.write("âœ… **Etap 2/4:** WstÄ™pne wyszukiwanie kandydatÃ³w...")
                embeddings_matrix = np.vstack(df['embedding'].values)
                similarity_matrix = cosine_similarity(embeddings_matrix)
                
                st.write(f"âœ… **Etap 3/4:** Åadowanie modelu Jina Reranker...")
                with st.spinner("Model Jina Reranker Å‚aduje siÄ™ tylko za pierwszym razem, proszÄ™ czekaÄ‡..."):
                    reranker = load_reranker_model(RERANKER_MODEL)

                st.write(f"âœ… **Etap 4/4:** Precyzyjny Reranking z Jina...")
                progress_bar_rerank = st.progress(0, text="Reranking...")
                
                all_results = []
                for idx in range(len(df)):
                    source_text = df[column_to_embed].iloc[idx]
                    candidate_indices = similarity_matrix[idx].argsort()[-(NUM_CANDIDATES + 1):-1][::-1]
                    candidate_texts = df[column_to_embed].iloc[candidate_indices].tolist()
                    
                    reranked_results = reranker.rank(
                        source_text,
                        candidate_texts,
                        return_documents=False,
                        top_k=NUM_FINAL_RESULTS
                    )
                    
                    original_urls = df['url'].iloc[candidate_indices].tolist()
                    top_urls = [original_urls[res['corpus_id']] for res in reranked_results]

                    result_row = {'original_url': df['url'].iloc[idx]}
                    for i, url in enumerate(top_urls):
                        result_row[f'rekomendowany_link_{i+1}'] = url
                    all_results.append(result_row)

                    progress_bar_rerank.progress((idx + 1) / len(df), text=f"Reranking... {idx + 1}/{len(df)}")

                progress_bar_rerank.empty()
                output_df = pd.DataFrame(all_results)
                st.success("ðŸŽ‰ Analiza zakoÅ„czona pomyÅ›lnie!")
                st.dataframe(output_df.head())
                csv_output = output_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ðŸ“¥ Pobierz wyniki (output_jina_reranked.csv)",
                    data=csv_output,
                    file_name='output_jina_reranked.csv',
                    mime='text/csv',
                )
        except Exception as e:
            st.error(f"WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d podczas przetwarzania: {e}")
            st.warning("SprawdÅº swÃ³j klucz API, limity konta oraz poÅ‚Ä…czenie z internetem.")


# ==============================================================================
# TRYB 2: LINKOWANIE KRZYÅ»OWE (DWA PLIKI)
# ==============================================================================
else:
    st.info(
        """
        **Proces:** Model znajduje powiÄ…zania semantyczne miÄ™dzy dwoma rÃ³Å¼nymi listami URL-i (np. kategorie i blog).
        **Wynik:** Dwa arkusze - jeden z rekomendacjami z Pliku 2 dla Pliku 1, a drugi odwrotnie.
        """
    )
    
    try:
        api_key = st.secrets["OPENAI_API_KEY"]
    except KeyError:
        st.error("BÅ‚Ä…d: Klucz OPENAI_API_KEY nie zostaÅ‚ ustawiony w sekretach aplikacji!")
        st.info("PrzejdÅº do ustawieÅ„ aplikacji w Streamlit Community Cloud i dodaj swÃ³j klucz.")
        st.stop()

    col1, col2 = st.columns(2)
    with col1:
        uploaded_file_1 = st.file_uploader("1. Wgraj Plik 1 (np. Kategorie)", type=["csv"])
        column_to_embed_1 = st.selectbox("Wybierz kolumnÄ™ dla Pliku 1", ("h1", "title"), key="col1_select")

    with col2:
        uploaded_file_2 = st.file_uploader("2. Wgraj Plik 2 (np. Blog)", type=["csv"])
        column_to_embed_2 = st.selectbox("Wybierz kolumnÄ™ dla Pliku 2", ("h1", "title"), key="col2_select")

    if st.button("ðŸš€ Uruchom analizÄ™ krzyÅ¼owÄ…", disabled=(uploaded_file_1 is None or uploaded_file_2 is None)):
        try:
            df1 = pd.read_csv(uploaded_file_1)
            df2 = pd.read_csv(uploaded_file_2)

            if 'url' not in df1.columns or 'url' not in df2.columns:
                st.error("Oba pliki muszÄ… zawieraÄ‡ kolumnÄ™ 'url'.")
            else:
                texts1 = df1[column_to_embed_1].fillna(" ").tolist()
                embeddings1 = get_embeddings(texts1, EMBEDDING_MODEL, api_key, "Plik 1")

                texts2 = df2[column_to_embed_2].fillna(" ").tolist()
                embeddings2 = get_embeddings(texts2, EMBEDDING_MODEL, api_key, "Plik 2")

                matrix1 = np.vstack(embeddings1)
                matrix2 = np.vstack(embeddings2)

                st.write("âœ… **Obliczanie podobieÅ„stwa i reranking...**")
                similarity_matrix_1_vs_2 = cosine_similarity(matrix1, matrix2)
                
                with st.spinner("Model Jina Reranker Å‚aduje siÄ™ tylko za pierwszym razem, proszÄ™ czekaÄ‡..."):
                    reranker = load_reranker_model(RERANKER_MODEL)
                
                # --- Przetwarzanie 1 -> 2 ---
                results_1_to_2 = []
                for idx in range(len(df1)):
                    source_text = texts1[idx]
                    candidate_indices = similarity_matrix_1_vs_2[idx].argsort()[-NUM_CANDIDATES:][::-1]
                    candidate_texts = [texts2[i] for i in candidate_indices]
                    
                    reranked_results = reranker.rank(source_text, candidate_texts, top_k=NUM_FINAL_RESULTS, return_documents=False)
                    
                    original_urls_candidates = df2['url'].iloc[candidate_indices].tolist()
                    top_urls = [original_urls_candidates[res['corpus_id']] for res in reranked_results]
                    
                    result_row = {'original_url_plik_1': df1['url'].iloc[idx]}
                    for i, url in enumerate(top_urls):
                        result_row[f'rekomendowany_link_z_pliku_2_{i+1}'] = url
                    results_1_to_2.append(result_row)
                output_df_1_to_2 = pd.DataFrame(results_1_to_2)
                
                # --- Przetwarzanie 2 -> 1 ---
                similarity_matrix_2_vs_1 = similarity_matrix_1_vs_2.T
                results_2_to_1 = []
                for idx in range(len(df2)):
                    source_text = texts2[idx]
                    candidate_indices = similarity_matrix_2_vs_1[idx].argsort()[-NUM_CANDIDATES:][::-1]
                    candidate_texts = [texts1[i] for i in candidate_indices]

                    reranked_results = reranker.rank(source_text, candidate_texts, top_k=NUM_FINAL_RESULTS, return_documents=False)
                    
                    original_urls_candidates = df1['url'].iloc[candidate_indices].tolist()
                    top_urls = [original_urls_candidates[res['corpus_id']] for res in reranked_results]
                    
                    result_row = {'original_url_plik_2': df2['url'].iloc[idx]}
                    for i, url in enumerate(top_urls):
                        result_row[f'rekomendowany_link_z_pliku_1_{i+1}'] = url
                    results_2_to_1.append(result_row)
                output_df_2_to_1 = pd.DataFrame(results_2_to_1)

                st.success("ðŸŽ‰ Analiza krzyÅ¼owa zakoÅ„czona pomyÅ›lnie!")
                
                st.subheader("Wyniki: Rekomendacje z Pliku 2 dla Pliku 1")
                st.dataframe(output_df_1_to_2.head())
                
                st.subheader("Wyniki: Rekomendacje z Pliku 1 dla Pliku 2")
                st.dataframe(output_df_2_to_1.head())
                
                output_excel = BytesIO()
                with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
                    output_df_1_to_2.to_excel(writer, sheet_name='Rekomendacje_dla_Pliku_1', index=False)
                    output_df_2_to_1.to_excel(writer, sheet_name='Rekomendacje_dla_Pliku_2', index=False)
                
                st.download_button(
                    label="ðŸ“¥ Pobierz wyniki (plik Excel)",
                    data=output_excel.getvalue(),
                    file_name='cross_linking_results.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
        except Exception as e:
            st.error(f"WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d: {e}")
