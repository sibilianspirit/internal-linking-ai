import streamlit as st
import pandas as pd
from openai import OpenAI
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
# ZMIANA 1: Poprawny import z biblioteki sentence-transformers
from sentence_transformers import CrossEncoder
import time

# --- Konfiguracja strony Streamlit ---
st.set_page_config(page_title="AI do Linkowania Wewnƒôtrznego", layout="centered")
st.title("ü§ñ AI do Linkowania Wewnƒôtrznego")
analysis_mode = st.radio(
    "Wybierz tryb analizy:",
    ("Linkowanie Wewnƒôtrzne (jeden plik)", "Linkowanie Krzy≈ºowe (dwa pliki)"),
    horizontal=True
)

if analysis_mode == "Linkowanie Wewnƒôtrzne (jeden plik)":
    # --- Tutaj wklej ca≈Çy istniejƒÖcy kod logiki dla jednego pliku ---
    # (od st.info(...) a≈º do samego ko≈Ñca)
    st.info(...) # i tak dalej
    uploaded_file = st.file_uploader(...)
    # ... reszta starego kodu
else: # analysis_mode == "Linkowanie Krzy≈ºowe (dwa pliki)"
    # --- Tutaj zdefiniujemy nowƒÖ logikƒô dla dw√≥ch plik√≥w ---
    st.info(
        """
        **Proces:** Model znajduje powiƒÖzania semantyczne miƒôdzy dwoma r√≥≈ºnymi listami URL-i (np. kategorie i blog).
        **Wynik:** Dwa arkusze - jeden z rekomendacjami z Pliku 2 dla Pliku 1, a drugi odwrotnie.
        """
    )
st.info(
    """
    **Etapy procesu:**
    1. **Wyszukiwanie -** model embeddingowy znajduje 10 potencjalnych kandydat√≥w.
    2. **Reranking -** model rerankingowy precyzyjnie ocenia tych 10 kandydat√≥w, aby wybraƒá 5 najlepszych.

    **Wymagania:**
    1. **Plik CSV -** musi zawieraƒá kolumny: `url`, `h1`, `title`.
    2. **Wyb√≥r pomiƒôdzy h1 i title -** wska≈º, na kt√≥rej kolumnie ma bazowaƒá model.
    """
)
try:
    api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    # ... obs≈Çuga b≈Çƒôdu klucza API (bez zmian)

# Interfejs dla dw√≥ch plik√≥w
col1, col2 = st.columns(2)
with col1:
    uploaded_file_1 = st.file_uploader("1. Wgraj Plik 1 (np. Kategorie)", type=["csv"])
    column_to_embed_1 = st.selectbox("Wybierz kolumnƒô dla Pliku 1", ("h1", "title"), key="col1_select")

with col2:
    uploaded_file_2 = st.file_uploader("2. Wgraj Plik 2 (np. Blog)", type=["csv"])
    column_to_embed_2 = st.selectbox("Wybierz kolumnƒô dla Pliku 2", ("h1", "title"), key="col2_select")

if st.button("üöÄ Uruchom analizƒô krzy≈ºowƒÖ", disabled=(uploaded_file_1 is None or uploaded_file_2 is None)):
    try:
        df1 = pd.read_csv(uploaded_file_1)
        df2 = pd.read_csv(uploaded_file_2)

        # Walidacja kolumn (mo≈ºna rozbudowaƒá)
        if 'url' not in df1.columns or 'url' not in df2.columns:
            st.error("Oba pliki muszƒÖ zawieraƒá kolumnƒô 'url'.")
        else:
            # ETAP 1: Generowanie embedding√≥w dla obu plik√≥w
            st.write("‚úÖ **Etap 1/4:** Generowanie embedding√≥w dla Pliku 1...")
            texts1 = df1[column_to_embed_1].fillna(" ").tolist()
            embeddings1 = get_embeddings(texts1, EMBEDDING_MODEL, api_key)

            st.write("‚úÖ **Etap 2/4:** Generowanie embedding√≥w dla Pliku 2...")
            texts2 = df2[column_to_embed_2].fillna(" ").tolist()
            embeddings2 = get_embeddings(texts2, EMBEDDING_MODEL, api_key)

            # Przygotowanie macierzy
            matrix1 = np.vstack(embeddings1)
            matrix2 = np.vstack(embeddings2)

            # ETAP 3: Obliczanie podobie≈Ñstwa krzy≈ºowego
            st.write("‚úÖ **Etap 3/4:** Obliczanie podobie≈Ñstwa i reranking...")
            similarity_matrix_1_vs_2 = cosine_similarity(matrix1, matrix2)

            # ≈Åadowanie modelu rerankujƒÖcego
            reranker = load_reranker_model(RERANKER_MODEL)
            
            # ETAP 4: Przetwarzanie wynik√≥w w obie strony
            
            # --- Przetwarzanie 1 -> 2 (np. Kategorie -> Blog) ---
            results_1_to_2 = []
            for idx in range(len(df1)):
                source_text = texts1[idx]
                # Znajd≈∫ kandydat√≥w z pliku 2
                candidate_indices = similarity_matrix_1_vs_2[idx].argsort()[-NUM_CANDIDATES:][::-1]
                candidate_texts = [texts2[i] for i in candidate_indices]
                
                # Reranking
                reranked_results = reranker.rank(source_text, candidate_texts, top_k=NUM_FINAL_RESULTS)
                
                # Zbieranie wynik√≥w
                original_urls_candidates = df2['url'].iloc[candidate_indices].tolist()
                top_urls = [original_urls_candidates[res['corpus_id']] for res in reranked_results]
                
                result_row = {'original_url': df1['url'].iloc[idx]}
                for i, url in enumerate(top_urls):
                    result_row[f'rekomendowany_link_{i+1}'] = url
                results_1_to_2.append(result_row)

            output_df_1_to_2 = pd.DataFrame(results_1_to_2)
            
            # --- Przetwarzanie 2 -> 1 (np. Blog -> Kategorie) ---
            # U≈ºywamy transpozycji macierzy podobie≈Ñstwa, aby uniknƒÖƒá ponownych oblicze≈Ñ
            similarity_matrix_2_vs_1 = similarity_matrix_1_vs_2.T
            results_2_to_1 = []
            for idx in range(len(df2)):
                source_text = texts2[idx]
                # Znajd≈∫ kandydat√≥w z pliku 1
                candidate_indices = similarity_matrix_2_vs_1[idx].argsort()[-NUM_CANDIDATES:][::-1]
                candidate_texts = [texts1[i] for i in candidate_indices]

                # Reranking
                reranked_results = reranker.rank(source_text, candidate_texts, top_k=NUM_FINAL_RESULTS)
                
                # Zbieranie wynik√≥w
                original_urls_candidates = df1['url'].iloc[candidate_indices].tolist()
                top_urls = [original_urls_candidates[res['corpus_id']] for res in reranked_results]
                
                result_row = {'original_url': df2['url'].iloc[idx]}
                for i, url in enumerate(top_urls):
                    result_row[f'rekomendowany_link_{i+1}'] = url
                results_2_to_1.append(result_row)
            
            output_df_2_to_1 = pd.DataFrame(results_2_to_1)

            st.success("üéâ Analiza krzy≈ºowa zako≈Ñczona pomy≈õlnie!")
            
            # Wy≈õwietlanie wynik√≥w
            st.subheader("Wyniki: Plik 1 -> Plik 2")
            st.dataframe(output_df_1_to_2.head())
            
            st.subheader("Wyniki: Plik 2 -> Plik 1")
            st.dataframe(output_df_2_to_1.head())
            
            # Pobieranie wynik√≥w jako plik Excel z dwoma arkuszami
            # Do tego potrzebna bƒôdzie nowa biblioteka: openpyxl
            from io import BytesIO
            output_excel = BytesIO()
            with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
                output_df_1_to_2.to_excel(writer, sheet_name='Plik1_do_Pliku2', index=False)
                output_df_2_to_1.to_excel(writer, sheet_name='Plik2_do_Pliku1', index=False)
            
            st.download_button(
                label="üì• Pobierz wyniki (plik Excel)",
                data=output_excel.getvalue(),
                file_name='cross_linking_results.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )

    except Exception as e:
        st.error(f"WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd: {e}")
# --- Sta≈Çe konfiguracyjne ---
EMBEDDING_MODEL = 'text-embedding-3-large'
RERANKER_MODEL = 'jinaai/jina-reranker-v2-base-multilingual' 
NUM_CANDIDATES = 10
NUM_FINAL_RESULTS = 5

# --- Funkcje pomocnicze ---

@st.cache_data
def get_embeddings(texts: list[str], model: str, api_key: str) -> list[list[float]]:
    client = OpenAI(api_key=api_key)
    embeddings = []
    batch_size = 100
    progress_bar = st.progress(0, text="Etap 1: Generowanie embedding√≥w...")
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch = [text if isinstance(text, str) and text.strip() != "" else " " for text in batch]
        response = client.embeddings.create(input=batch, model=model)
        embeddings.extend([item.embedding for item in response.data])
        progress_val = min((i + batch_size) / len(texts), 1.0)
        progress_text = f"Etap 1: Generowanie embedding√≥w... Przetworzono {min(i + batch_size, len(texts))}/{len(texts)} URLi."
        progress_bar.progress(progress_val, text=progress_text)
        time.sleep(0.5)
    progress_bar.empty()
    return embeddings

@st.cache_resource
def load_reranker_model(model_name: str):
    """≈Åaduje model CrossEncoder z pamiƒôci podrƒôcznej."""
    # ZMIANA 2: U≈ºywamy klasy CrossEncoder do za≈Çadowania modelu
    # max_length jest wa≈ºne dla d≈Çu≈ºszych tekst√≥w, zgodnie z dokumentacjƒÖ modelu
    return CrossEncoder(model_name, max_length=1024, trust_remote_code=True)

# --- G≈Ç√≥wna logika aplikacji ---
try:
    api_key = st.secrets["OPENAI_API_KEY"]
except KeyError:
    st.error("B≈ÇƒÖd: Klucz OPENAI_API_KEY nie zosta≈Ç ustawiony w sekretach aplikacji!")
    st.info("Przejd≈∫ do ustawie≈Ñ aplikacji w Streamlit Community Cloud i dodaj sw√≥j klucz.")
    st.stop()

uploaded_file = st.file_uploader("1. Wgraj plik CSV", type=["csv"], help="Upewnij siƒô, ≈ºe plik zawiera kolumny: 'url', 'title' oraz 'h1'.")
column_to_embed = st.selectbox("2. Wybierz kolumnƒô do analizy", ("h1", "title"), disabled=uploaded_file is None)

if st.button("üöÄ Uruchom analizƒô z Jina Reranker", disabled=(uploaded_file is None)):
    try:
        df = pd.read_csv(uploaded_file)
        required_columns = ['url', 'title', 'h1']
        if not all(col in df.columns for col in required_columns):
            st.error(f"B≈ÇƒÖd: Plik CSV musi zawieraƒá kolumny: {', '.join(required_columns)}")
        else:
            st.write("‚úÖ **Etap 1/4:** Generowanie embedding√≥w...")
            texts_to_embed = df[column_to_embed].fillna(" ").tolist()
            df['embedding'] = get_embeddings(texts_to_embed, EMBEDDING_MODEL, api_key)
            
            st.write("‚úÖ **Etap 2/4:** Wstƒôpne wyszukiwanie kandydat√≥w...")
            embeddings_matrix = np.vstack(df['embedding'].values)
            similarity_matrix = cosine_similarity(embeddings_matrix)
            
            st.write(f"‚úÖ **Etap 3/4:** ≈Åadowanie modelu Jina Reranker...")
            with st.spinner("Model Jina Reranker ≈Çaduje siƒô tylko za pierwszym razem, proszƒô czekaƒá..."):
                reranker = load_reranker_model(RERANKER_MODEL)

            st.write(f"‚úÖ **Etap 4/4:** Precyzyjny Reranking z Jina...")
            progress_bar_rerank = st.progress(0, text="Reranking...")
            
            all_results = []
            for idx in range(len(df)):
                source_text = df[column_to_embed].iloc[idx]
                candidate_indices = similarity_matrix[idx].argsort()[-(NUM_CANDIDATES + 1):-1][::-1]
                candidate_texts = df[column_to_embed].iloc[candidate_indices].tolist()
                
                # ZMIANA 3: U≈ºywamy metody .rank() z odpowiednimi parametrami
                reranked_results = reranker.rank(
                    source_text,
                    candidate_texts,
                    return_documents=False, # Nie potrzebujemy tekstu, tylko indeksy
                    top_k=NUM_FINAL_RESULTS
                )
                
                # ZMIANA 4: Wynik to lista s≈Çownik√≥w, np. [{'corpus_id': 2, 'score': 0.9}, ...]
                # Dostosowujemy klucz z 'index' na 'corpus_id'
                original_urls = df['url'].iloc[candidate_indices].tolist()
                top_urls = [original_urls[res['corpus_id']] for res in reranked_results]

                result_row = {'original_url': df['url'].iloc[idx]}
                for i, url in enumerate(top_urls):
                    result_row[f'rekomendowany_link_{i+1}'] = url
                all_results.append(result_row)

                progress_bar_rerank.progress((idx + 1) / len(df), text=f"Reranking... {idx + 1}/{len(df)}")

            progress_bar_rerank.empty()
            output_df = pd.DataFrame(all_results)
            st.success("üéâ Analiza zako≈Ñczona pomy≈õlnie!")
            st.dataframe(output_df.head())
            csv_output = output_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Pobierz wyniki (output_jina_reranked.csv)",
                data=csv_output,
                file_name='output_jina_reranked.csv',
                mime='text/csv',
            )
    except Exception as e:
        st.error(f"WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas przetwarzania: {e}")
        st.warning("Sprawd≈∫ sw√≥j klucz API, limity konta oraz po≈ÇƒÖczenie z internetem.")

